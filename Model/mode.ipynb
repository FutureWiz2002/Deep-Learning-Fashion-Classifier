{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf \n",
    "import tensorflow_datasets as tfds\n",
    "import math \n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt\n",
    "import logging \n",
    "import cv2 as cv\n",
    "\n",
    "datasets, metadata = tfds.load('fashion_mnist', as_supervised=True, with_info=True) # Loads the data\n",
    "train_dataset, test_dataset = datasets['train'], datasets['test'] # Splits the dataset \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat', 'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']\n",
      "FeaturesDict({\n",
      "    'image': Image(shape=(28, 28, 1), dtype=uint8),\n",
      "    'label': ClassLabel(shape=(), dtype=int64, num_classes=10),\n",
      "})\n",
      "Number of training examples: 60000\n",
      "Number of test examples:     10000\n"
     ]
    }
   ],
   "source": [
    "class_name = metadata.features['label'].names # Prints the names of the labels\n",
    "print(class_name)\n",
    "print(metadata.features) # Prints the features\n",
    "\n",
    "\n",
    "num_train_examples = metadata.splits['train'].num_examples\n",
    "num_test_examples = metadata.splits['test'].num_examples\n",
    "print(\"Number of training examples: {}\".format(num_train_examples))\n",
    "print(\"Number of test examples:     {}\".format(num_test_examples))\n",
    "\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Flatten(input_shape=(28, 28, 1)), #flattens the 3d image into one array of numbers\n",
    "    tf.keras.layers.Dense(512, activation=tf.nn.relu), #creates 128 level of neural networks\n",
    "    tf.keras.layers.Dense(512, activation=tf.nn.relu),\n",
    "    tf.keras.layers.Dense(512, activation=tf.nn.relu),\n",
    "    tf.keras.layers.Dense(10, activation=tf.nn.softmax) #softmax produces probability distribution \n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n",
    "              metrics=['accuracy']) \n",
    "\n",
    "BATCH_SIZE = 32 #Batch size is the number of iterations the neural network does before it is updated \n",
    "train_dataset = train_dataset.cache().repeat().shuffle(num_train_examples).batch(BATCH_SIZE) #Updates dataset with batch included\n",
    "test_dataset = test_dataset.cache().batch(BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "311/313 [============================>.] - ETA: 0s - loss: 4.6921 - accuracy: 0.7127\n",
      "Epoch 1: saving model to training_2\\cp.ckpt\n",
      "313/313 [==============================] - 7s 14ms/step - loss: 4.6708 - accuracy: 0.7128\n",
      "Epoch 2/10\n",
      "310/313 [============================>.] - ETA: 0s - loss: 0.8691 - accuracy: 0.7664\n",
      "Epoch 2: saving model to training_2\\cp.ckpt\n",
      "313/313 [==============================] - 4s 14ms/step - loss: 0.8675 - accuracy: 0.7662\n",
      "Epoch 3/10\n",
      "313/313 [==============================] - ETA: 0s - loss: 0.6689 - accuracy: 0.7903\n",
      "Epoch 3: saving model to training_2\\cp.ckpt\n",
      "313/313 [==============================] - 4s 14ms/step - loss: 0.6689 - accuracy: 0.7903\n",
      "Epoch 4/10\n",
      "312/313 [============================>.] - ETA: 0s - loss: 0.5762 - accuracy: 0.8081\n",
      "Epoch 4: saving model to training_2\\cp.ckpt\n",
      "313/313 [==============================] - 4s 14ms/step - loss: 0.5759 - accuracy: 0.8080\n",
      "Epoch 5/10\n",
      "311/313 [============================>.] - ETA: 0s - loss: 0.5335 - accuracy: 0.8134\n",
      "Epoch 5: saving model to training_2\\cp.ckpt\n",
      "313/313 [==============================] - 4s 14ms/step - loss: 0.5328 - accuracy: 0.8133\n",
      "Epoch 6/10\n",
      "310/313 [============================>.] - ETA: 0s - loss: 0.5215 - accuracy: 0.8191\n",
      "Epoch 6: saving model to training_2\\cp.ckpt\n",
      "313/313 [==============================] - 4s 14ms/step - loss: 0.5202 - accuracy: 0.8196\n",
      "Epoch 7/10\n",
      "311/313 [============================>.] - ETA: 0s - loss: 0.4869 - accuracy: 0.8247\n",
      "Epoch 7: saving model to training_2\\cp.ckpt\n",
      "313/313 [==============================] - 4s 14ms/step - loss: 0.4871 - accuracy: 0.8245\n",
      "Epoch 8/10\n",
      "313/313 [==============================] - ETA: 0s - loss: 0.5038 - accuracy: 0.8200\n",
      "Epoch 8: saving model to training_2\\cp.ckpt\n",
      "313/313 [==============================] - 4s 14ms/step - loss: 0.5038 - accuracy: 0.8200\n",
      "Epoch 9/10\n",
      "311/313 [============================>.] - ETA: 0s - loss: 0.4306 - accuracy: 0.8438\n",
      "Epoch 9: saving model to training_2\\cp.ckpt\n",
      "313/313 [==============================] - 4s 14ms/step - loss: 0.4299 - accuracy: 0.8438\n",
      "Epoch 10/10\n",
      "311/313 [============================>.] - ETA: 0s - loss: 0.4417 - accuracy: 0.8328\n",
      "Epoch 10: saving model to training_2\\cp.ckpt\n",
      "313/313 [==============================] - 4s 14ms/step - loss: 0.4413 - accuracy: 0.8331\n",
      "313/313 [==============================] - 2s 5ms/step - loss: 0.5160 - accuracy: 0.8236\n",
      "Accuracy on test dataset: 0.8235999941825867\n",
      "Loss:  0.5160253643989563\n",
      "1/1 [==============================] - 0s 176ms/step\n",
      "4\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "checkpoint_path = \"training_2/cp.ckpt\"\n",
    "checkpoint_dir = os.path.dirname(checkpoint_path)\n",
    "cp_callback = tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_path,\n",
    "                                                 save_weights_only=True,\n",
    "                                                 verbose=1)\n",
    "\n",
    "model.fit(train_dataset, epochs=10, steps_per_epoch=math.ceil(num_test_examples/32), callbacks=[cp_callback])\n",
    "\n",
    "model.save_weights(\"model_weights\")\n",
    "test_loss, test_accuracy = model.evaluate(test_dataset, steps=math.ceil(num_test_examples/32))\n",
    "print('Accuracy on test dataset:', test_accuracy)\n",
    "print('Loss: ', test_loss)\n",
    "\n",
    "for test_images, test_labels in test_dataset.take(1): #predict one sample from the data\n",
    "  test_images = test_images.numpy()\n",
    "  test_labels = test_labels.numpy()\n",
    "  predictions = model.predict(test_images)\n",
    "\n",
    "predictions.shape\n",
    "print(np.argmax(predictions[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "[[1.22523670e-05 1.55056156e-07 1.92017779e-01 3.33811295e-05\n",
      "  8.07420313e-01 1.18348620e-08 5.14241692e-04 1.26773714e-09\n",
      "  1.87289845e-06 3.71303793e-10]\n",
      " [6.93838656e-01 8.33966420e-04 1.40907206e-02 2.31047738e-02\n",
      "  4.40708362e-03 2.04402080e-04 2.61413336e-01 1.19777927e-04\n",
      "  1.94419979e-03 4.31628432e-05]\n",
      " [5.01720118e-04 3.18449056e-05 6.87812626e-01 1.50179223e-03\n",
      "  3.00302327e-01 3.60631384e-06 9.82900802e-03 1.61783623e-06\n",
      "  1.54843965e-05 1.82601596e-08]\n",
      " [2.05344870e-04 2.31395532e-07 1.55342162e-01 5.78116626e-04\n",
      "  7.97043920e-01 5.86962460e-06 4.67895940e-02 1.66062350e-07\n",
      "  3.45452427e-05 1.51823670e-07]\n",
      " [1.18436707e-04 7.87085014e-07 5.23225553e-02 2.06580735e-03\n",
      "  5.84135473e-01 1.18945791e-05 3.61330450e-01 2.33992205e-06\n",
      "  1.11464524e-05 1.17829131e-06]\n",
      " [4.38045930e-07 7.90240706e-10 1.04090236e-06 2.16013540e-09\n",
      "  2.70014516e-06 9.99951839e-01 9.98044669e-08 4.27755440e-05\n",
      "  3.46409195e-07 7.58577244e-07]\n",
      " [3.35168753e-17 1.00000000e+00 8.32809742e-18 8.82181860e-13\n",
      "  7.54577250e-17 1.92758964e-20 1.70472011e-16 5.43149944e-22\n",
      "  3.98538928e-19 1.89630366e-25]\n",
      " [1.30929882e-04 1.66087222e-04 2.08844885e-05 8.66768023e-05\n",
      "  2.11767237e-05 9.37146172e-02 3.42447893e-05 8.29567432e-01\n",
      "  2.57886807e-03 7.36791193e-02]\n",
      " [1.69718694e-02 9.32118739e-04 5.01408577e-01 4.14618850e-02\n",
      "  2.26176068e-01 8.14109761e-03 1.99858010e-01 1.17254164e-03\n",
      "  3.34004546e-03 5.37759741e-04]\n",
      " [2.42584432e-03 1.37898198e-03 5.61229706e-01 2.45618867e-03\n",
      "  1.32555917e-01 8.52259924e-04 2.96787173e-01 7.87516532e-04\n",
      "  1.31412386e-03 2.12341212e-04]\n",
      " [1.21892386e-04 4.14211245e-04 4.31902117e-06 9.99437511e-01\n",
      "  3.12167708e-06 1.59940626e-07 1.86413890e-05 1.02988222e-10\n",
      "  1.48343005e-07 3.54894651e-12]\n",
      " [2.30238264e-04 2.96961980e-06 1.69479445e-01 4.91281552e-03\n",
      "  4.65558290e-01 4.16754956e-05 3.59758824e-01 1.59177694e-06\n",
      "  1.24595008e-05 1.67804785e-06]\n",
      " [1.07820088e-03 8.98926344e-04 4.70096588e-01 8.67763720e-03\n",
      "  4.80428368e-01 8.51258756e-06 3.87210138e-02 1.95324501e-05\n",
      "  6.61513768e-05 5.07678124e-06]\n",
      " [9.86920622e-06 1.33629507e-08 4.90233712e-02 1.40104792e-04\n",
      "  7.43360460e-01 1.01241915e-06 2.07463816e-01 1.04275877e-07\n",
      "  1.06558764e-06 1.72121659e-07]\n",
      " [7.62347263e-05 3.19561138e-07 1.29406676e-01 3.23584565e-04\n",
      "  7.83878744e-01 3.08519907e-06 8.63058418e-02 2.95439776e-07\n",
      "  4.94536744e-06 2.72691011e-07]\n",
      " [7.76408076e-01 1.15737039e-05 1.30117091e-03 9.67535283e-03\n",
      "  1.01331185e-04 5.61864044e-06 2.12403342e-01 8.34615785e-05\n",
      "  5.97871394e-06 3.98686234e-06]\n",
      " [3.60425729e-05 1.06836455e-06 3.52516651e-01 1.19553180e-04\n",
      "  5.80957353e-01 8.51668119e-07 6.63497224e-02 2.12762956e-07\n",
      "  1.84922555e-05 5.32234701e-08]\n",
      " [3.68979465e-11 3.36208738e-16 1.65544966e-14 1.01116667e-11\n",
      "  6.75692012e-17 1.00000000e+00 3.75411487e-16 2.22376926e-08\n",
      "  3.32460771e-14 1.25177008e-10]\n",
      " [7.82915522e-05 7.06264771e-08 4.62635035e-06 1.16194215e-07\n",
      "  3.02777653e-06 1.37159941e-06 2.17460969e-04 1.77695961e-06\n",
      "  9.99684930e-01 8.33079048e-06]\n",
      " [4.79390474e-05 1.91702600e-08 6.09251128e-06 3.79479980e-06\n",
      "  1.54859572e-06 6.76436303e-03 2.32573420e-05 5.38738370e-02\n",
      "  6.41889164e-06 9.39272702e-01]\n",
      " [1.34695756e-05 3.77956167e-06 9.34878528e-01 9.04970511e-06\n",
      "  2.54734270e-02 3.15918598e-08 3.96180451e-02 3.14383399e-08\n",
      "  3.67840721e-06 1.61818489e-10]\n",
      " [9.34362644e-04 1.83787968e-04 2.51397694e-04 4.57665956e-05\n",
      "  1.02185273e-04 2.84946322e-01 3.60337988e-04 2.48728931e-01\n",
      "  3.86347979e-01 7.80989379e-02]\n",
      " [7.12564729e-10 9.99998689e-01 7.73998254e-10 1.14156921e-06\n",
      "  9.47744780e-08 4.33720464e-12 8.65555272e-09 2.77912719e-12\n",
      "  2.99746556e-12 3.61583500e-15]\n",
      " [4.95585482e-06 3.13710134e-11 1.03093917e-07 2.01157832e-07\n",
      "  2.48807748e-08 6.06180576e-04 2.22276253e-06 1.48049919e-02\n",
      "  1.88037092e-07 9.84581053e-01]\n",
      " [2.66151852e-04 1.12906741e-06 3.94451527e-05 1.72158525e-05\n",
      "  1.06552552e-05 2.35540085e-02 3.76176176e-05 1.00596271e-01\n",
      "  1.59058749e-04 8.75318527e-01]\n",
      " [3.09028872e-03 4.54811752e-01 2.84447312e-01 1.11010736e-02\n",
      "  1.11407451e-01 4.61233518e-04 1.32622406e-01 8.34300357e-04\n",
      "  1.08763680e-03 1.36614399e-04]\n",
      " [6.22834477e-06 1.14025696e-08 1.00489490e-01 4.41286356e-05\n",
      "  8.55015576e-01 3.62079106e-07 4.44430299e-02 5.02198727e-09\n",
      "  1.17796264e-06 9.22962684e-09]\n",
      " [5.34997184e-07 9.99930739e-01 4.37575545e-06 5.88303374e-05\n",
      "  5.22719893e-06 6.01631911e-10 2.31565082e-07 5.17450180e-11\n",
      "  3.13421378e-09 5.00332501e-12]\n",
      " [3.61753345e-01 9.23777893e-02 1.33496672e-02 3.02620590e-01\n",
      "  8.47891718e-03 9.46666114e-03 1.88192174e-01 5.99117484e-03\n",
      "  1.68589763e-02 9.10624163e-04]\n",
      " [7.15688009e-10 2.34376076e-13 1.46109392e-11 9.15799311e-11\n",
      "  8.98082719e-11 9.99998689e-01 2.68991796e-14 1.26869747e-06\n",
      "  1.33210976e-09 5.69471474e-08]\n",
      " [3.97221884e-03 2.51900419e-05 4.80663683e-03 1.51176151e-04\n",
      "  2.66860356e-03 5.81354974e-03 5.26097510e-03 1.53197744e-03\n",
      "  9.75088894e-01 6.80785975e-04]\n",
      " [9.55713630e-01 1.03253614e-10 6.02331129e-05 1.92689360e-04\n",
      "  2.21374208e-07 1.23569976e-09 4.40314710e-02 1.73522722e-06\n",
      "  7.66010722e-09 5.70138270e-10]]\n",
      "4\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "for test_images, test_labels in test_dataset.take(3): #predict one sample from the data\n",
    "  test_images = test_images.numpy()\n",
    "  test_labels = test_labels.numpy()\n",
    "  # print(type(test_images), (test_labels))\n",
    "  # print(test_labels)\n",
    "  # plt.imshow(test_images)\n",
    "  predictions = model.predict(test_images)\n",
    "\n",
    "predictions.shape\n",
    "print(predictions)\n",
    "print(np.argmax(predictions[0]))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
